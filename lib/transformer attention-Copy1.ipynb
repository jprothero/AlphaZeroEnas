{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T19:11:14.070506Z",
     "start_time": "2018-05-07T19:11:14.003005Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class EncoderOnly(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, d_model, layer, N, dropout=0.1):\n",
    "        super(EncoderOnly, self).__init__()\n",
    "        self.pe = PositionalEncoding(d_model, dropout)\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        x = self.pe(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "def initialize(module):\n",
    "    for p in module.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "\n",
    "def make_model(src_vocab, per_layer_embeddings, N=2, \n",
    "               d_model=128, d_ff=512, h=2, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "#     position = PositionalEncoding(d_model, dropout)\n",
    "\n",
    "    enc = EncoderOnly(d_model, EncoderLayer(d_model, c(attn), c(ff), dropout), N, dropout)\n",
    "    \n",
    "    decoders = []\n",
    "    for num_embs in per_layer_embeddings:\n",
    "        decoders.append(nn.Sequential(*[\n",
    "            Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N)\n",
    "            , Generator(d_model, num_embs)\n",
    "        ]))\n",
    "#     dec = Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N)\n",
    "#     gen = Generator(d_model, tgt_vocab)\n",
    "#     components = [enc, dec, src_emb, tgt_emb, gen]\n",
    "        \n",
    "    for dec in decoders:\n",
    "        initialize(dec)\n",
    "        \n",
    "    initialize(enc)\n",
    "    \n",
    "    return enc, decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T19:11:14.693904Z",
     "start_time": "2018-05-07T19:11:14.688851Z"
    }
   },
   "outputs": [],
   "source": [
    "options_in = 35\n",
    "per_layer_options_out = [5, 4]\n",
    "d_model = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T19:11:15.112467Z",
     "start_time": "2018-05-07T19:11:15.020136Z"
    }
   },
   "outputs": [],
   "source": [
    "enc, decoders = make_model(options_in, per_layer_options_out, d_model=d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T19:11:15.257051Z",
     "start_time": "2018-05-07T19:11:15.238189Z"
    }
   },
   "outputs": [],
   "source": [
    "from ipdb import set_trace\n",
    "import numpy as np\n",
    "\n",
    "embeddings = torch.rand(options_in, d_model)\n",
    "\n",
    "batch_of_embeddings = [embeddings.clone().unsqueeze(0) for _ in range(batch_size)]\n",
    "batch_of_embeddings = torch.cat(batch_of_embeddings)\n",
    "\n",
    "batch_of_masks = torch.tensor(np.random.randint(options_in, size=(batch_size, 1))).float()\n",
    "\n",
    "for emb, mask in zip(batch_of_embeddings, batch_of_masks):\n",
    "    emb[mask.int().item():] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T19:11:17.358065Z",
     "start_time": "2018-05-07T19:11:16.689301Z"
    }
   },
   "outputs": [],
   "source": [
    "encode_step = enc(batch_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T19:11:27.568403Z",
     "start_time": "2018-05-07T19:11:27.496943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6065e+00, -1.5170e-01,  8.0579e-01,  ...,  5.6617e-01,\n",
       "           7.5357e-01,  1.5010e-01],\n",
       "         [-5.4105e-01,  1.9623e-01,  6.6845e-01,  ...,  1.3914e+00,\n",
       "          -2.2179e-01,  8.7144e-01],\n",
       "         [ 1.7966e-01, -1.3180e+00,  1.1345e+00,  ...,  1.4641e+00,\n",
       "           8.8721e-01,  4.1921e-02],\n",
       "         ...,\n",
       "         [-1.0597e+00,  2.7805e-01,  6.2312e-02,  ...,  9.4419e-01,\n",
       "           7.1273e-01,  2.3636e-01],\n",
       "         [-2.9419e-01, -5.2450e-02,  2.5608e-01,  ...,  1.2792e+00,\n",
       "           5.6235e-01,  3.1980e-02],\n",
       "         [-8.7824e-01, -2.3800e-01,  7.5172e-01,  ...,  1.3273e+00,\n",
       "           6.7777e-01,  8.7528e-01]],\n",
       "\n",
       "        [[-1.4586e+00,  7.8804e-01, -7.9737e-01,  ...,  1.4474e+00,\n",
       "          -6.0273e-01, -2.3895e-01],\n",
       "         [-1.1197e+00, -1.2546e+00,  5.3635e-01,  ...,  1.3617e+00,\n",
       "           5.2885e-01,  4.9019e-01],\n",
       "         [-1.2900e-03, -1.0283e+00,  8.7424e-01,  ...,  1.8584e+00,\n",
       "           7.3960e-02,  3.9833e-01],\n",
       "         ...,\n",
       "         [-7.7543e-01,  2.6086e-02, -1.3425e-01,  ...,  1.6355e+00,\n",
       "           1.6762e-01,  4.2629e-01],\n",
       "         [ 1.4657e-01, -7.1749e-01,  3.9463e-01,  ...,  3.4318e-01,\n",
       "           3.4494e-01,  1.2560e+00],\n",
       "         [-1.9574e-01, -1.3218e+00,  5.0275e-01,  ...,  1.2553e+00,\n",
       "          -6.2715e-01,  1.7972e-01]],\n",
       "\n",
       "        [[-3.2171e-01,  6.4804e-01,  1.1499e+00,  ..., -5.0914e-01,\n",
       "          -1.9430e-01, -2.3314e-01],\n",
       "         [-3.9506e-01,  4.9342e-01,  8.7587e-01,  ...,  1.0643e+00,\n",
       "           6.5151e-01,  3.1044e-01],\n",
       "         [ 7.8687e-02, -7.9611e-01,  7.9025e-01,  ...,  1.2683e+00,\n",
       "           3.6593e-01, -1.0759e-01],\n",
       "         ...,\n",
       "         [-1.0491e+00,  4.9329e-01, -2.7751e-01,  ..., -4.4019e-01,\n",
       "           1.0693e+00,  7.1649e-01],\n",
       "         [ 1.7528e-01, -4.6407e-01, -1.6106e-01,  ...,  8.0696e-01,\n",
       "           7.2426e-01, -2.0930e-01],\n",
       "         [-6.5365e-01, -5.8360e-01,  6.1081e-01,  ...,  1.0599e+00,\n",
       "           6.1852e-01,  1.2010e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.2906e+00,  1.7813e+00,  5.5385e-01,  ...,  9.2637e-01,\n",
       "           1.0386e+00, -5.8242e-01],\n",
       "         [-3.5973e-01,  5.4326e-02,  6.7985e-01,  ..., -4.6914e-02,\n",
       "           4.9854e-01,  2.7450e-01],\n",
       "         [-1.7417e-01, -8.4116e-01,  1.1404e+00,  ..., -7.3143e-02,\n",
       "           5.3778e-01, -1.6682e-01],\n",
       "         ...,\n",
       "         [-8.4653e-02,  5.1831e-01,  3.0081e-01,  ...,  2.8878e-01,\n",
       "           5.2924e-01, -7.9784e-03],\n",
       "         [ 2.8679e-01, -1.9490e-01,  1.2398e-01,  ...,  1.2199e+00,\n",
       "           5.6873e-01,  2.4110e-01],\n",
       "         [-9.3224e-01, -1.0268e+00,  5.7527e-01,  ...,  1.2699e+00,\n",
       "           4.6792e-01, -4.7879e-02]],\n",
       "\n",
       "        [[-1.8042e+00,  5.3363e-01,  1.6161e+00,  ...,  2.5938e-01,\n",
       "           2.3550e-01, -2.1855e-01],\n",
       "         [-2.5054e-01, -5.3005e-02,  6.0699e-01,  ...,  1.0320e+00,\n",
       "           7.1117e-02,  7.2241e-01],\n",
       "         [ 8.7348e-01, -1.3508e+00,  3.3581e-01,  ...,  1.4433e+00,\n",
       "           2.9884e-01,  4.9401e-01],\n",
       "         ...,\n",
       "         [-3.9871e-01,  7.3399e-01, -1.8129e-01,  ...,  5.8773e-02,\n",
       "          -3.5634e-01,  2.1158e-01],\n",
       "         [-1.3344e-01, -4.8258e-01, -1.3199e-01,  ...,  1.4541e+00,\n",
       "           4.1658e-01,  4.6398e-01],\n",
       "         [-7.0524e-01, -1.3852e+00, -1.5646e-01,  ...,  1.2884e+00,\n",
       "           2.8121e-01,  3.7342e-01]],\n",
       "\n",
       "        [[-1.5502e+00,  8.6515e-01,  1.7543e-01,  ...,  1.2019e+00,\n",
       "           8.0575e-01,  3.1767e-01],\n",
       "         [-1.4596e-01,  4.6736e-02,  6.9145e-01,  ...,  1.0830e+00,\n",
       "           3.0161e-01,  5.6192e-01],\n",
       "         [ 5.1170e-02, -1.2481e+00,  9.1375e-01,  ...,  2.1339e+00,\n",
       "           1.2573e-01,  1.1366e+00],\n",
       "         ...,\n",
       "         [-6.9720e-01,  3.6575e-01,  9.8374e-01,  ...,  1.1353e+00,\n",
       "           4.4982e-01,  5.2045e-01],\n",
       "         [-4.4733e-02, -8.4686e-01,  3.7771e-01,  ...,  7.4815e-01,\n",
       "           1.0794e+00,  2.3331e-01],\n",
       "         [-2.2323e-01, -1.5137e+00,  7.3425e-01,  ..., -1.2306e-01,\n",
       "           8.6295e-01,  4.8998e-01]]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T16:38:17.303853Z",
     "start_time": "2018-05-07T16:38:17.298361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 35, 128])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_step.shape\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T16:16:11.394132Z",
     "start_time": "2018-05-07T16:16:11.390710Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# enc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
